{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f2ec35",
   "metadata": {},
   "source": [
    "\n",
    "# CS667 Project 2 – Regression on Retail Sales (End-to-End)\n",
    "This notebook covers: data prep, feature engineering, train/test split, model training (Linear, Tree, RandomForest, GradientBoosting), evaluation (R², MAE, MSE, RMSE), and plots (correlation heatmap, actual vs predicted, residuals, feature importances).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a44b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup\n",
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "DATA_PATH = \"/mnt/data/retail_data_synthetic_50k.xlsx\"\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e628be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize columns and detect target\n",
    "df.columns = [c.strip().replace(\"\\n\",\" \").replace(\"\\r\",\" \") for c in df.columns]\n",
    "\n",
    "possible_targets = [\"Total Amount\",\"Total_Amount\",\"total_amount\",\"TOTAL_AMOUNT\",\"Revenue\",\"Sales\",\"Total\",\"Amount\"]\n",
    "target_col = None\n",
    "for cand in possible_targets:\n",
    "    if cand in df.columns:\n",
    "        target_col = cand\n",
    "        break\n",
    "if target_col is None:\n",
    "    candidates = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    target_col = candidates[-1]\n",
    "print(\"Target column:\", target_col)\n",
    "\n",
    "# Date features (if available)\n",
    "date_cols = [c for c in df.columns if \"date\" in c.lower()]\n",
    "if date_cols:\n",
    "    dcol = date_cols[0]\n",
    "    df[dcol] = pd.to_datetime(df[dcol], errors=\"coerce\")\n",
    "    df[\"year\"] = df[dcol].dt.year\n",
    "    df[\"month\"] = df[dcol].dt.month\n",
    "    df[\"dayofweek\"] = df[dcol].dt.dayofweek\n",
    "    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5,6]).astype(int)\n",
    "\n",
    "    def month_to_season(m):\n",
    "        if pd.isna(m):\n",
    "            return np.nan\n",
    "        m = int(m)\n",
    "        if m in [12,1,2]: return \"winter\"\n",
    "        if m in [3,4,5]:  return \"spring\"\n",
    "        if m in [6,7,8]:  return \"summer\"\n",
    "        return \"fall\"\n",
    "    df[\"season\"] = df[\"month\"].apply(month_to_season)\n",
    "\n",
    "# Feature selection\n",
    "id_like = set([\"Transaction ID\",\"Transaction_ID\",\"transaction_id\",\"Customer ID\",\"Customer_ID\",\"customer_id\"])\n",
    "feature_cols = [c for c in df.columns if c != target_col and c not in id_like]\n",
    "\n",
    "numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = [c for c in feature_cols if c not in numeric_cols]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                                      (\"scaler\", StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                                          (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[(\"num\", numeric_transformer, numeric_cols),\n",
    "                  (\"cat\", categorical_transformer, categorical_cols)]\n",
    ")\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Train/Test shapes:\", X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d40ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and evaluate models\n",
    "candidates = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "def evaluate_model(name, model):\n",
    "    pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    r2 = metrics.r2_score(y_test, preds)\n",
    "    mae = metrics.mean_absolute_error(y_test, preds)\n",
    "    mse = metrics.mean_squared_error(y_test, preds)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return name, pipe, r2, mae, mse, rmse, preds\n",
    "\n",
    "records = []\n",
    "for name, model in candidates.items():\n",
    "    try:\n",
    "        rec = evaluate_model(name, model)\n",
    "        records.append(rec)\n",
    "    except Exception as e:\n",
    "        print(\"[Warn] Skipping\", name, \"->\", e)\n",
    "\n",
    "perf = pd.DataFrame([{\"Model\": r[0], \"R2\": r[2], \"MAE\": r[3], \"MSE\": r[4], \"RMSE\": r[5]} for r in records])\n",
    "perf.sort_values([\"R2\",\"RMSE\"], ascending=[False, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pick best model\n",
    "records_sorted = sorted(records, key=lambda r: (r[2], -r[5]), reverse=True)\n",
    "best = records_sorted[0]\n",
    "best_name, best_pipe, r2, mae, mse, rmse, preds = best\n",
    "print(\"Best model:\", best_name, \"| R2:\", r2, \"| RMSE:\", rmse)\n",
    "perf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dea9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correlation heatmap\n",
    "num_for_corr = df.select_dtypes(include=[np.number])\n",
    "if num_for_corr.shape[1] >= 2:\n",
    "    corr = num_for_corr.corr(numeric_only=True)\n",
    "    plt.figure()\n",
    "    plt.imshow(corr.values, interpolation=\"nearest\")\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.index)), corr.index)\n",
    "    plt.title(\"Correlation Heatmap (Numeric Features)\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a5c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Actual vs Predicted\n",
    "plt.figure()\n",
    "plt.scatter(y_test, preds, alpha=0.5)\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(f\"Actual vs Predicted ({best_name})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11dc9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Residuals plot\n",
    "residuals = y_test - preds\n",
    "plt.figure()\n",
    "plt.scatter(preds, residuals, alpha=0.5)\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residuals (Actual - Predicted)\")\n",
    "plt.title(f\"Residual Plot ({best_name})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db02913",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature importances / coefficients\n",
    "try:\n",
    "    ohe = best_pipe.named_steps[\"preprocess\"].named_transformers_[\"cat\"].named_steps[\"encoder\"] if \"cat\" in best_pipe.named_steps[\"preprocess\"].transformers_[1][0] else None\n",
    "except Exception:\n",
    "    try:\n",
    "        ohe = best_pipe.named_steps[\"preprocess\"].named_transformers_[\"cat\"].named_steps[\"encoder\"]\n",
    "    except Exception:\n",
    "        ohe = None\n",
    "\n",
    "if ohe is None:\n",
    "    try:\n",
    "        ohe = best_pipe.named_steps[\"preprocess\"].named_transformers_[\"cat\"].named_steps[\"encoder\"]\n",
    "    except Exception:\n",
    "        ohe = None\n",
    "\n",
    "num_features = numeric_cols\n",
    "cat_features = list(ohe.get_feature_names_out(categorical_cols)) if ohe is not None else []\n",
    "all_features = list(num_features) + list(cat_features)\n",
    "\n",
    "model_obj = best_pipe.named_steps[\"model\"]\n",
    "importances = None\n",
    "if hasattr(model_obj, \"feature_importances_\"):\n",
    "    importances = model_obj.feature_importances_\n",
    "elif hasattr(model_obj, \"coef_\"):\n",
    "    coef = model_obj.coef_\n",
    "    importances = coef if np.ndim(coef) == 1 else coef.ravel()\n",
    "\n",
    "if importances is not None and len(all_features) == len(importances):\n",
    "    fi = pd.DataFrame({ \"feature\": all_features, \"importance\": np.abs(importances) }).sort_values(\"importance\", ascending=False).head(25)\n",
    "    plt.figure(figsize=(8, max(4, len(fi)*0.3)))\n",
    "    plt.barh(fi[\"feature\"], fi[\"importance\"])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(f\"Top Feature Importances ({best_name})\")\n",
    "    plt.xlabel(\"Importance (abs)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fi.head(25)\n",
    "else:\n",
    "    print(\"Feature importances/coefficients not available or length mismatch.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
